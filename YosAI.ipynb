{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YosAI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZaneZaiontz/YosAI/blob/main/YosAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZEHKSK-q8sO"
      },
      "source": [
        "**TODO:**\n",
        "\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEYA9jFmRG6t"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL18W5HvRGN1"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import random as rand\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhoAxUfXq4TY"
      },
      "source": [
        "Open dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMoxvg3NrBei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f343844-032a-4860-9b47-4f17ee8a5dd4"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open('./zhaoClean.txt', 'r').read()#.decode(encoding='utf-8').lower()\n",
        "# num chars in file\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 256636 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmBIleLGq4ia"
      },
      "source": [
        "Encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIYw88NhPTrt",
        "outputId": "f30e3400-b46b-4f8f-f093-477afc29e881"
      },
      "source": [
        "vocab1 = {}\n",
        "currCode = 1\n",
        "def wordEncode(text):\n",
        "  global currCode\n",
        "\n",
        "  words = text.lower().split(' ')\n",
        "  #t1=''.join(words)\n",
        "  #words = t1.split(' ')\n",
        "  \n",
        "  #print(words[20])\n",
        "\n",
        "\n",
        "  encoding = []\n",
        "\n",
        "  for word in words:\n",
        "    if word in vocab1:\n",
        "      code = vocab1[word]\n",
        "      encoding.append(code)\n",
        "    else:\n",
        "      vocab1[word] = currCode\n",
        "      encoding.append(currCode)\n",
        "      currCode += 1\n",
        "  \n",
        "  return encoding\n",
        "\n",
        "#text = \"this is a test to see if this test will work is is test a a\"\n",
        "encoding = wordEncode(text)\n",
        "print(encoding[90:1000])\n",
        "print(vocab1['why'])\n",
        "print(len(vocab1))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[79, 80, 81, 82, 83, 84, 85, 86, 87, 3, 88, 89, 90, 6, 91, 92, 93, 3, 94, 95, 96, 97, 98, 6, 99, 100, 35, 101, 102, 103, 104, 105, 106, 107, 108, 109, 35, 110, 111, 112, 113, 114, 6, 115, 116, 117, 94, 118, 119, 120, 121, 122, 6, 123, 124, 1, 125, 126, 127, 128, 129, 130, 126, 6, 131, 6, 132, 3, 133, 3, 134, 135, 136, 137, 3, 138, 47, 139, 140, 6, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 3, 1, 151, 152, 153, 154, 155, 3, 156, 157, 158, 6, 159, 160, 161, 149, 1, 162, 163, 164, 165, 47, 6, 166, 167, 168, 169, 170, 6, 171, 3, 6, 172, 173, 174, 175, 176, 177, 178, 69, 179, 180, 3, 6, 181, 182, 183, 184, 47, 6, 185, 186, 47, 187, 188, 189, 190, 191, 192, 1, 193, 194, 195, 196, 197, 198, 199, 200, 3, 201, 92, 163, 202, 203, 149, 204, 205, 206, 207, 35, 208, 209, 6, 210, 211, 1, 212, 213, 214, 215, 3, 216, 217, 218, 219, 6, 220, 221, 222, 223, 224, 225, 226, 204, 227, 1, 228, 1, 229, 230, 231, 232, 233, 234, 235, 69, 236, 237, 238, 239, 32, 240, 241, 153, 242, 243, 244, 245, 6, 246, 247, 248, 249, 250, 251, 175, 252, 253, 254, 255, 256, 6, 257, 3, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 3, 271, 192, 272, 273, 69, 274, 6, 275, 276, 277, 278, 279, 280, 219, 6, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 6, 298, 299, 149, 6, 300, 47, 204, 301, 6, 302, 303, 304, 3, 305, 306, 307, 6, 308, 309, 310, 26, 6, 311, 312, 47, 6, 313, 314, 315, 26, 316, 317, 318, 6, 319, 3, 6, 320, 321, 322, 323, 35, 324, 325, 326, 327, 328, 35, 329, 330, 331, 332, 333, 334, 335, 304, 3, 336, 337, 338, 334, 339, 340, 341, 342, 343, 344, 345, 346, 3, 347, 348, 6, 349, 350, 351, 352, 353, 354, 355, 356, 357, 32, 358, 359, 32, 360, 175, 3, 6, 361, 362, 363, 364, 365, 366, 6, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 366, 382, 383, 384, 385, 386, 387, 388, 389, 384, 390, 391, 94, 392, 393, 394, 395, 396, 397, 1, 398, 399, 400, 401, 402, 1, 403, 291, 125, 404, 405, 406, 407, 32, 408, 409, 410, 157, 411, 412, 413, 276, 414, 415, 416, 417, 418, 252, 419, 420, 421, 422, 423, 6, 424, 47, 425, 426, 427, 428, 429, 430, 18, 431, 432, 47, 6, 433, 434, 435, 436, 437, 438, 439, 47, 6, 440, 35, 441, 152, 442, 443, 47, 6, 444, 445, 446, 6, 447, 448, 107, 449, 450, 451, 62, 410, 452, 453, 454, 319, 69, 455, 456, 457, 6, 458, 459, 47, 56, 460, 327, 334, 461, 3, 1, 462, 463, 464, 243, 35, 465, 3, 146, 466, 467, 468, 316, 469, 470, 334, 471, 472, 338, 334, 473, 199, 474, 3, 475, 476, 338, 477, 6, 478, 479, 480, 481, 6, 482, 483, 484, 485, 486, 487, 149, 6, 488, 489, 490, 491, 98, 6, 89, 492, 493, 3, 1, 494, 495, 496, 497, 47, 6, 498, 499, 6, 500, 501, 502, 309, 35, 503, 504, 6, 505, 506, 507, 508, 509, 69, 316, 510, 511, 6, 512, 513, 514, 515, 516, 517, 47, 6, 518, 92, 519, 149, 6, 520, 153, 521, 522, 6, 523, 524, 525, 6, 526, 49, 527, 528, 6, 529, 530, 531, 532, 69, 6, 533, 534, 535, 536, 537, 538, 539, 6, 540, 541, 542, 543, 544, 455, 545, 3, 1, 546, 175, 3, 547, 548, 549, 550, 1, 551, 552, 485, 553, 91, 554, 353, 555, 556, 557, 558, 62, 559, 560, 561, 562, 563, 564, 6, 125, 565, 1, 566, 567, 568, 569, 570, 3, 571, 152, 572, 573, 149, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 1, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 3, 152, 599, 600, 6, 601, 602, 603, 604, 149, 6, 605, 26, 606, 6, 607, 608, 609, 20, 610, 611, 612, 613, 614, 615, 616, 617, 618, 208, 619, 35, 620, 621, 622, 32, 623, 624, 625, 626, 149, 627, 152, 628, 629, 630, 3, 631, 35, 632, 633, 634, 635, 47, 6, 636, 539, 6, 637, 638, 6, 639, 640, 641, 525, 6, 91, 642, 204, 643, 644, 541, 645, 646, 647, 1, 648, 649, 650, 3, 651, 652, 3, 653, 345, 654, 655, 656, 657, 658, 304, 3, 659, 6, 660, 661, 653, 662, 663, 664, 485, 665, 3, 666, 667, 668, 219, 6, 669, 670, 125, 671, 3, 672, 673, 265, 149, 204, 674, 6, 56, 3, 675, 67, 676, 677, 6, 678, 91, 679, 680, 681, 6, 682, 683, 3, 684, 685, 6, 686, 49, 687, 628, 6, 688, 149, 6, 658, 689, 690, 6, 691, 692, 175, 693, 694, 695, 696, 697, 698, 699, 700, 701, 69, 702, 35, 703, 704, 705, 60, 706, 6, 707, 708, 522, 709, 710, 711, 712, 69, 6, 713, 714, 715, 716, 717, 3, 718, 719, 720, 6, 721, 722, 316, 723, 490, 1, 724, 149, 6, 725, 726, 727, 728, 471, 729, 730]\n",
            "9578\n",
            "15735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zFRb1y9q4v1"
      },
      "source": [
        "Step 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cToLhQWbrCJR"
      },
      "source": [
        "seq_length = 16\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoding)\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ani7b8QBq46H"
      },
      "source": [
        "Step 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VehZSG8A5sK1"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5U2foZxNDwT"
      },
      "source": [
        "Build Model/Shuffle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTgZzCfBrCdt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f759c33-5b31-4b9a-b084-193973bc0ffe"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab1)  # vocab is number of unique characters\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 2048\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)])\n",
        "  return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           4028160   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (64, None, 2048)          18882560  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 15735)         32241015  \n",
            "=================================================================\n",
            "Total params: 55,151,735\n",
            "Trainable params: 55,151,735\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSJU9H7s7lEs"
      },
      "source": [
        "Compile/Loss Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MksqLEpy7ldn"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtsk91CZ8Txx"
      },
      "source": [
        "Checkpoints/Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6W0Awyz8UDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3614d0e-ac85-4287-8ec8-5e51d8f718c5"
      },
      "source": [
        "checkpoint_dir = './trainCKPT'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"CKPT-{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True)\n",
        "history = model.fit(data, epochs=40, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "29/29 [==============================] - 14s 120ms/step - loss: 9.3425\n",
            "Epoch 2/40\n",
            "29/29 [==============================] - 4s 117ms/step - loss: 8.4853\n",
            "Epoch 3/40\n",
            "29/29 [==============================] - 4s 119ms/step - loss: 8.1606\n",
            "Epoch 4/40\n",
            "29/29 [==============================] - 4s 118ms/step - loss: 7.9588\n",
            "Epoch 5/40\n",
            "29/29 [==============================] - 4s 118ms/step - loss: 7.8503\n",
            "Epoch 6/40\n",
            "29/29 [==============================] - 4s 120ms/step - loss: 7.6840\n",
            "Epoch 7/40\n",
            "29/29 [==============================] - 4s 120ms/step - loss: 7.4921\n",
            "Epoch 8/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 7.3028\n",
            "Epoch 9/40\n",
            "29/29 [==============================] - 4s 121ms/step - loss: 7.0093\n",
            "Epoch 10/40\n",
            "29/29 [==============================] - 4s 122ms/step - loss: 6.6363\n",
            "Epoch 11/40\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 6.2183\n",
            "Epoch 12/40\n",
            "29/29 [==============================] - 4s 125ms/step - loss: 5.7481\n",
            "Epoch 13/40\n",
            "29/29 [==============================] - 4s 125ms/step - loss: 5.2618\n",
            "Epoch 14/40\n",
            "29/29 [==============================] - 4s 127ms/step - loss: 4.7666\n",
            "Epoch 15/40\n",
            "29/29 [==============================] - 4s 126ms/step - loss: 4.3106\n",
            "Epoch 16/40\n",
            "29/29 [==============================] - 4s 127ms/step - loss: 3.7946\n",
            "Epoch 17/40\n",
            "29/29 [==============================] - 4s 131ms/step - loss: 3.3664\n",
            "Epoch 18/40\n",
            "29/29 [==============================] - 4s 130ms/step - loss: 2.9215\n",
            "Epoch 19/40\n",
            "29/29 [==============================] - 4s 132ms/step - loss: 2.5805\n",
            "Epoch 20/40\n",
            "29/29 [==============================] - 4s 133ms/step - loss: 2.2993\n",
            "Epoch 21/40\n",
            "29/29 [==============================] - 4s 135ms/step - loss: 2.0271\n",
            "Epoch 22/40\n",
            "29/29 [==============================] - 4s 133ms/step - loss: 1.8465\n",
            "Epoch 23/40\n",
            "29/29 [==============================] - 4s 132ms/step - loss: 1.6783\n",
            "Epoch 24/40\n",
            "29/29 [==============================] - 4s 131ms/step - loss: 1.5413\n",
            "Epoch 25/40\n",
            "29/29 [==============================] - 4s 132ms/step - loss: 1.4309\n",
            "Epoch 26/40\n",
            "29/29 [==============================] - 4s 132ms/step - loss: 1.3261\n",
            "Epoch 27/40\n",
            "29/29 [==============================] - 4s 135ms/step - loss: 1.2138\n",
            "Epoch 28/40\n",
            "29/29 [==============================] - 4s 132ms/step - loss: 1.1335\n",
            "Epoch 29/40\n",
            "29/29 [==============================] - 4s 133ms/step - loss: 1.0628\n",
            "Epoch 30/40\n",
            "29/29 [==============================] - 4s 131ms/step - loss: 1.0029\n",
            "Epoch 31/40\n",
            "29/29 [==============================] - 4s 134ms/step - loss: 0.9386\n",
            "Epoch 32/40\n",
            "29/29 [==============================] - 4s 135ms/step - loss: 0.8845\n",
            "Epoch 33/40\n",
            "29/29 [==============================] - 4s 133ms/step - loss: 0.8377\n",
            "Epoch 34/40\n",
            "29/29 [==============================] - 4s 134ms/step - loss: 0.7830\n",
            "Epoch 35/40\n",
            "29/29 [==============================] - 4s 133ms/step - loss: 0.7523\n",
            "Epoch 36/40\n",
            "29/29 [==============================] - 5s 135ms/step - loss: 0.7219\n",
            "Epoch 37/40\n",
            "29/29 [==============================] - 4s 136ms/step - loss: 0.6716\n",
            "Epoch 38/40\n",
            "29/29 [==============================] - 4s 134ms/step - loss: 0.6488\n",
            "Epoch 39/40\n",
            "29/29 [==============================] - 4s 141ms/step - loss: 0.6059\n",
            "Epoch 40/40\n",
            "29/29 [==============================] - 4s 131ms/step - loss: 0.5927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apXh5a-U8knS"
      },
      "source": [
        "Build"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f96y2tYY8k6Y"
      },
      "source": [
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5BT2rdl8oNt"
      },
      "source": [
        "Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2VXDtFK8sa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc056d5-5ae5-4979-f586-254e74164a12"
      },
      "source": [
        "def generate_text(model):\n",
        "\n",
        "  start = rand.randint(1, 15735) # TODO: Maybe syllable or word\n",
        "  startWord = get_key(start)\n",
        "  # Vectorizing start char\n",
        "  input_eval = [vocab1[get_key(start)]]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store results\n",
        "  txtGen = []\n",
        "\n",
        "  model.reset_states()\n",
        "  while True:\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "    \n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      txtGen.append(get_key(predicted_id))\n",
        "      txtGen.append(' ')\n",
        "      txtGen\n",
        "      if syllable_count(''.join(txtGen)) > 17:\n",
        "        break\n",
        "  return (''.join(txtGen))\n",
        "\n",
        "def get_key(val):\n",
        "  for key, value in vocab1.items():\n",
        "    if val == value:\n",
        "      return key\n",
        "\n",
        "def syllable_count(word):\n",
        "    word = word.lower()\n",
        "    count = 0\n",
        "    vowels = \"aeiouy\"\n",
        "    if word[0] in vowels:\n",
        "        count += 1\n",
        "    for index in range(1, len(word)):\n",
        "        if word[index] in vowels and word[index - 1] not in vowels:\n",
        "            count += 1\n",
        "    if word.endswith(\"e\"):\n",
        "        count -= 1\n",
        "    if count == 0:\n",
        "        count += 1\n",
        "    return count\n",
        "\n",
        "def toHaiku(arr):\n",
        "  i = 0\n",
        "  firCheck = False\n",
        "  secCheck = False\n",
        "  retArr = []\n",
        "  for word in arr:\n",
        "    if word == '\\n':\n",
        "      continue\n",
        "\n",
        "    i+=syllable_count(word)\n",
        "    retArr.append(word)\n",
        "    if i > 12 and not secCheck:\n",
        "      retArr.append('\\n')\n",
        "      secCheck = True\n",
        "    if i > 5 and not firCheck:\n",
        "      retArr.append('\\n')\n",
        "      firCheck = True\n",
        "\n",
        "\n",
        "  return ' '.join(retArr)\n",
        "\n",
        "\n",
        "rawOut = generate_text(model)\n",
        "\n",
        "rawOut = rawOut.split('\\n')\n",
        "rawOut = ' '.join(rawOut)\n",
        "\n",
        "rawArr = rawOut.split(' ')\n",
        "del rawArr[-1]\n",
        "printST = toHaiku(rawArr)\n",
        "\n",
        "print(printST)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "field empty bunch machine \n",
            " which news from - chat light uphill \n",
            " spring distant echo across\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bof2QSQx8vkI"
      },
      "source": [
        "**Output**\n"
      ]
    }
  ]
}