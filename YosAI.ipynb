{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YosAI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZaneZaiontz/YosAI/blob/main/YosAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEYA9jFmRG6t"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhciIDZgwhlQ"
      },
      "source": [
        "Opening and reading in data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMoxvg3NrBei"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import random as rand\n",
        "\n",
        "def readFiles():\n",
        "    file = open('./zhaoClean.txt', 'r')\n",
        "    lines = file.readlines()\n",
        "    file.close()\n",
        "    file = open('./zhaoClean.txt', 'r')\n",
        "    return file.read().lower(), lines\n",
        "\n",
        "text, lines = readFiles()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmBIleLGq4ia"
      },
      "source": [
        "Encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIYw88NhPTrt"
      },
      "source": [
        "# training length\n",
        "sequenceLen = 64\n",
        "vocab = sorted(set(text))\n",
        "# Unique ID \n",
        "charToInt = {j:i for i, j in enumerate(vocab)}\n",
        "intToChar = np.array(vocab)\n",
        "\n",
        "examples_per_epoch = len(text)//(sequenceLen+1)\n",
        "tmpData = np.array([charToInt[i] for i in text])\n",
        "charData = tf.data.Dataset.from_tensor_slices(tmpData)\n",
        "sequences = charData.batch(sequenceLen+1, drop_remainder=True)\n",
        "\n",
        "def splitInput(chunk):  \n",
        "    inText = chunk[:-1]  \n",
        "    toText = chunk[1:] \n",
        "    return inText, toText \n",
        "\n",
        "dataset = sequences.map(splitInput)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5U2foZxNDwT"
      },
      "source": [
        "Build Model/Shuffle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBJW_puxaqAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b111c7-96b2-4441-d072-d5d95f88da24"
      },
      "source": [
        "sizeOfEmbed = 256\n",
        "sizeOfRNN = 1024\n",
        "sizeOfBuff = 10000\n",
        "sizeofBatch = 64\n",
        "sizeOfVocab = len(vocab)\n",
        "data = dataset.shuffle(sizeOfBuff).batch(sizeofBatch, drop_remainder=True)\n",
        "\n",
        "def buildTheModel(vocabSize, embedSize, rnnSize, batchSize):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocabSize, embedSize, batch_input_shape=[batchSize, None]),\n",
        "    tf.keras.layers.LSTM(rnnSize, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocabSize)])\n",
        "  return model\n",
        "model = buildTheModel(sizeOfVocab, sizeOfEmbed, sizeOfRNN, sizeofBatch)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           15360     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 60)            61500     \n",
            "=================================================================\n",
            "Total params: 5,323,836\n",
            "Trainable params: 5,323,836\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSJU9H7s7lEs"
      },
      "source": [
        "Compile/Loss Function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtsk91CZ8Txx"
      },
      "source": [
        "Checkpoints/Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6W0Awyz8UDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec79c6da-9c7e-40b4-8ce2-f3820042bf6e"
      },
      "source": [
        "numOfEpochs = 32\n",
        "\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "\n",
        "checkLocation = './trainingData'\n",
        "checkPre = os.path.join(checkLocation, \"CheckpointData_{epoch}\")\n",
        "\n",
        "checkBack=tf.keras.callbacks.ModelCheckpoint(filepath=checkPre, save_weights_only=True)\n",
        "history = model.fit(data, epochs=numOfEpochs, callbacks=[checkBack])\n",
        "\n",
        "model = buildTheModel(sizeOfVocab, sizeOfEmbed, sizeOfRNN, batchSize=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkLocation))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "61/61 [==============================] - 6s 45ms/step - loss: 3.2218\n",
            "Epoch 2/32\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 2.5569\n",
            "Epoch 3/32\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 2.3243\n",
            "Epoch 4/32\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 2.1728\n",
            "Epoch 5/32\n",
            "61/61 [==============================] - 3s 47ms/step - loss: 2.0658\n",
            "Epoch 6/32\n",
            "61/61 [==============================] - 3s 47ms/step - loss: 1.9725\n",
            "Epoch 7/32\n",
            "61/61 [==============================] - 3s 48ms/step - loss: 1.8792\n",
            "Epoch 8/32\n",
            "61/61 [==============================] - 3s 48ms/step - loss: 1.8026\n",
            "Epoch 9/32\n",
            "61/61 [==============================] - 3s 48ms/step - loss: 1.7392\n",
            "Epoch 10/32\n",
            "61/61 [==============================] - 3s 48ms/step - loss: 1.6875\n",
            "Epoch 11/32\n",
            "61/61 [==============================] - 3s 47ms/step - loss: 1.6367\n",
            "Epoch 12/32\n",
            "61/61 [==============================] - 3s 47ms/step - loss: 1.5927\n",
            "Epoch 13/32\n",
            "61/61 [==============================] - 3s 47ms/step - loss: 1.5614\n",
            "Epoch 14/32\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 1.5217\n",
            "Epoch 15/32\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 1.4929\n",
            "Epoch 16/32\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 1.4488\n",
            "Epoch 17/32\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 1.4335\n",
            "Epoch 18/32\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 1.4062\n",
            "Epoch 19/32\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 1.3700\n",
            "Epoch 20/32\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 1.3480\n",
            "Epoch 21/32\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 1.3193\n",
            "Epoch 22/32\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 1.2866\n",
            "Epoch 23/32\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 1.2580\n",
            "Epoch 24/32\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 1.2255\n",
            "Epoch 25/32\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 1.1941\n",
            "Epoch 26/32\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 1.1604\n",
            "Epoch 27/32\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 1.1284\n",
            "Epoch 28/32\n",
            "61/61 [==============================] - 3s 45ms/step - loss: 1.0934\n",
            "Epoch 29/32\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 1.0558\n",
            "Epoch 30/32\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 1.0193\n",
            "Epoch 31/32\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 0.9857\n",
            "Epoch 32/32\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5BT2rdl8oNt"
      },
      "source": [
        "Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2VXDtFK8sa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779db971-accc-44f7-9256-8c1c8e45d1e3"
      },
      "source": [
        "def generate_text(model):\n",
        "  newL = 0\n",
        "\n",
        "  startInt = (rand.randint(0, len(lines)))/3\n",
        "  startLine = lines[int(startInt)]\n",
        "  startLine = startLine.lower()\n",
        "\n",
        "  input_eval = [charToInt[s] for s in startLine]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "\n",
        "  model.reset_states()\n",
        "  while newL < 3:\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "      predictions = predictions\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "      \n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      if (intToChar[predicted_id] == '\\n'):\n",
        "        newL += 1\n",
        "      if (newL >= 3):\n",
        "        text_generated.append(intToChar[predicted_id])\n",
        "        break\n",
        "\n",
        "      text_generated.append(intToChar[predicted_id])\n",
        "\n",
        "  return (''.join(text_generated))\n",
        "\n",
        "print(generate_text(model))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "between snows fade\n",
            "intifaves\n",
            "at a cigame lanour him\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}